{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5430509-9f49-44cf-aea6-f96069a06eff",
   "metadata": {},
   "source": [
    "# Initial playground to test out different ways to train the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe344829-b518-4126-a989-b32ed55c1270",
   "metadata": {},
   "source": [
    "Nothing here is final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "909beff8-f60a-4cb6-8660-4286fdcbb88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torch.nn as nn\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21618907-8b57-4da1-9515-cc09aa615f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'train_batch':16,\n",
    "    'eval_batch':16,\n",
    "    'lr':0.005,\n",
    "    'model_name':'faster_rcnn_backbone'\n",
    "}\n",
    "model_name = params['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b14b40-d6ee-459f-868d-b651e5783d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed_value=4995):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f890b7-842d-4595-b253-e31137a2aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "746e677c-dd9c-428f-8632-a29c625c1a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9997d484-af1b-45b4-9837-adb39d6bce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandwrittenDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, visible_char_mapping, transform = None, image_resize = (1000,500), bad_classes = None):\n",
    "        \n",
    "        self.data = list(df.itertuples(index=False))\n",
    "        self.transform = transform\n",
    "        self.to_tensor = torchvision.transforms.ToTensor()\n",
    "        \n",
    "        self.visible_char_mapping = visible_char_mapping\n",
    "        \n",
    "        self.labels=np.zeros((len(self.data),len(visible_char_mapping)))\n",
    "        \n",
    "        for tup_idx, tup in enumerate(self.data):\n",
    "            visible_latex_chars = tup.visible_latex_chars\n",
    "            labels = [*map(self.visible_char_mapping.get, visible_latex_chars)]\n",
    "            \n",
    "            for char in labels:\n",
    "                self.labels[tup_idx, char - 1] = 1\n",
    "        \n",
    "        if bad_classes:\n",
    "            \n",
    "            new_data = []\n",
    "            for tup_idx, tup in enumerate(self.data):\n",
    "                visible_latex_chars = tup.visible_latex_chars\n",
    "                for label in visible_latex_chars:\n",
    "                    if label in bad_classes:\n",
    "                        new_data.append(tup)\n",
    "                        break\n",
    "            \n",
    "            self.data = new_data\n",
    "            self.labels=np.zeros((len(self.data),len(visible_char_mapping)))\n",
    "            for tup_idx, tup in enumerate(self.data):\n",
    "                visible_latex_chars = tup.visible_latex_chars\n",
    "                labels = [*map(self.visible_char_mapping.get, visible_latex_chars)]\n",
    "\n",
    "                for char in labels:\n",
    "                    self.labels[tup_idx, char - 1] = 1\n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        sample = self.data[index]\n",
    "        label = self.labels[index,:].astype(np.float32)\n",
    "        labels = torch.tensor(label)\n",
    "\n",
    "        \n",
    "        f_name = sample.filename\n",
    "        image = PIL.Image.open(f_name).convert(\"RGB\")\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, labels, f_name\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    To handle the data loading as different images may have different number \n",
    "    of objects and to handle varying size tensors as well.\n",
    "    \"\"\"\n",
    "    images = [img for img,_,_ in batch]\n",
    "    labels = torch.stack([lab for _, lab,_ in batch])\n",
    "    f_names = [f_n for _,_, f_n in batch]\n",
    "    \n",
    "    return images, labels, f_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb4774bc-a7e8-4650-b432-2784bc9048d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame(raw_data, image_path):\n",
    "    data = {}\n",
    "    data['latex'] = []\n",
    "    data['seq_len'] = []\n",
    "    data['latex_string'] = []\n",
    "    data['visible_latex_chars'] = []\n",
    "    data['filename'] = []\n",
    "    data['width'] = []\n",
    "    data['height'] = []\n",
    "    data['xmins_raw'] = []\n",
    "    data['xmaxs_raw'] = []\n",
    "    data['ymins_raw'] = []\n",
    "    data['ymaxs_raw'] = []\n",
    "    data['xmins'] = []\n",
    "    data['xmaxs'] = []\n",
    "    data['ymins'] = []\n",
    "    data['ymaxs'] = []\n",
    "    \n",
    "    for image in raw_data:\n",
    "        data['latex_string'].append(image['latex'])\n",
    "        data['latex'].append(image['image_data']['full_latex_chars'])\n",
    "        data['seq_len'].append(len(image['image_data']['full_latex_chars']))\n",
    "        data['visible_latex_chars'].append(image['image_data']['visible_latex_chars'])\n",
    "        data['filename'].append(os.path.join(image_path, image['filename']))\n",
    "        data['xmins_raw'].append(image['image_data']['xmins_raw'])\n",
    "        data['xmaxs_raw'].append(image['image_data']['xmaxs_raw'])\n",
    "        data['ymins_raw'].append(image['image_data']['ymins_raw'])\n",
    "        data['ymaxs_raw'].append(image['image_data']['ymaxs_raw'])\n",
    "        data['xmins'].append(image['image_data']['xmins'])\n",
    "        data['xmaxs'].append(image['image_data']['xmaxs'])\n",
    "        data['ymins'].append(image['image_data']['ymins'])\n",
    "        data['ymaxs'].append(image['image_data']['ymaxs'])\n",
    "        \n",
    "        data['width'].append(image['image_data']['width'])\n",
    "        data['height'].append(image['image_data']['height'])\n",
    "\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "079aea91-293d-4f14-bcc4-e2848d5d38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path = 'data/all_data.csv'):\n",
    "    if not os.path.isfile(path):\n",
    "        df = pd.DataFrame()\n",
    "        for i in range(1,11):\n",
    "            print(f'data/batch_{i}/JSON/kaggle_data_{i}.json')\n",
    "            with open(file=f'data/batch_{i}/JSON/kaggle_data_{i}.json') as f:\n",
    "                raw_data = json.load(f)\n",
    "            sub_df = create_data_frame(raw_data, f'data/batch_{i}/background_images')\n",
    "            df = df.append(sub_df)\n",
    "        df.to_csv(path)\n",
    "        df = pd.read_csv(path).drop(columns = 'Unnamed: 0')\n",
    "    else:\n",
    "        df = pd.read_csv(path).drop(columns = 'Unnamed: 0')\n",
    "\n",
    "    list_cols = ['xmins_raw', 'xmaxs_raw', 'ymins_raw', 'ymaxs_raw', 'xmins', 'xmaxs', 'ymins', 'ymaxs']\n",
    "    for c in list_cols:\n",
    "        df[c] = df[c].apply(json.loads)\n",
    "\n",
    "    df['latex'] = df['latex'].replace(\"'\\\\\\\\\", \"'\\\\\")\n",
    "    df['latex'] = df['latex'].apply(ast.literal_eval)\n",
    "    \n",
    "    #vocab = df['latex'].explode().unique().tolist()[0]\n",
    "    df['visible_latex_chars'] = df['visible_latex_chars'].replace(\"'\\\\\\\\\", \"'\\\\\")\n",
    "    df['visible_latex_chars'] = df['visible_latex_chars'].apply(ast.literal_eval)\n",
    "    \n",
    "    with open(file=f'data/extras/visible_char_map.json') as f:\n",
    "        visible_char_map = json.load(f)\n",
    "    \n",
    "    return df, visible_char_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fa33a7f-f4cc-40c3-b183-9e66081447c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df):\n",
    "    X_train, X_test = train_test_split(df, test_size=0.20, random_state=4995)\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "def prepare_data(batch_size = 32):\n",
    "    \n",
    "    df, visible_char_map = load_data()\n",
    "    \n",
    "    # num_classes = len(visible_char_map)\n",
    "    \n",
    "    l = []\n",
    "    for i in df['visible_latex_chars'].tolist():\n",
    "        for j in i:\n",
    "            l.append(j)\n",
    "    \n",
    "    classes = sorted(list(set(l)))\n",
    "    num_classes = len(set(l))\n",
    "    \n",
    "    visible_char_map = {}\n",
    "    for idx, symbol in enumerate(classes):\n",
    "        visible_char_map[symbol] = idx + 1 \n",
    "    \n",
    "    return df, visible_char_map, num_classes, classes\n",
    "\n",
    "def build_dataloaders(df, visible_char_map, df2 = None,  batch_size = 32, bad_classes = None):\n",
    "    data_transforms = {\n",
    "      'train': transforms.Compose([\n",
    "        #  transforms.Resize((896,896)),\n",
    "        #  transforms.RandomHorizontalFlip(),\n",
    "          transforms.ToTensor(),\n",
    "        #  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "      ]),\n",
    "      'val': transforms.Compose([\n",
    "       #   transforms.Resize((896,896)),\n",
    "          #transforms.CenterCrop(256),\n",
    "          #transforms.RandomHorizontalFlip(),\n",
    "          transforms.ToTensor(),\n",
    "       #   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "      ]),\n",
    "    }\n",
    "    \n",
    "    if df2 is None:\n",
    "        train_df, val_df = split_dataframe(df)\n",
    "    else:\n",
    "        train_df, val_df = df, df2\n",
    "    \n",
    "    train_dataset = HandwrittenDataset(train_df, visible_char_map, transform = data_transforms['train'], bad_classes = bad_classes)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers=1, collate_fn = collate_fn)\n",
    "    \n",
    "    val_dataset = HandwrittenDataset(val_df, visible_char_map, transform = data_transforms['val'], bad_classes = bad_classes)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False, num_workers=1, collate_fn = collate_fn)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e475e02-9245-44ff-914a-8f491e45da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(num_classes, model_path = 'models/resnet.pt', to_cuda = True):\n",
    "    if not model_path:\n",
    "        model = torchvision.models.resnet18(pretrained = True)\n",
    "        input_feat = model.fc.in_features\n",
    "        \n",
    "        model.fc = nn.Linear(input_feat, num_classes)\n",
    "        loaded_state_dict = False\n",
    "\n",
    "    else:\n",
    "        print(\"Loaded\", model_path)\n",
    "        model = torchvision.models.resnet18()\n",
    "        input_feat = model.fc.in_features\n",
    "        model.fc = nn.Linear(input_feat, num_classes)\n",
    "        loaded_model = torch.load(model_path)\n",
    "        model.load_state_dict(loaded_model)\n",
    "        loaded_state_dict = True\n",
    "        \n",
    "    if to_cuda:\n",
    "        model = model.to(DEVICE)\n",
    "        \n",
    "    return model, loaded_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b91f55a7-3b56-48e9-9aff-7a8141257988",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df, visible_char_map, num_classes, classes = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8579e3e-be8b-4d31-94c7-d01465bf8149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df_shuf = shuffle(df, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4093901-13d4-4c3f-ac6e-be68c1e97c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_df = df_shuf[:40000]\n",
    "val_df = df_shuf[40000:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be10a3a3-e0e5-4748-9c12-f5c8703f8d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df = df_shuf[5001:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0820b847-2d98-4d4c-a134-16e79fcf0166",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = build_dataloaders(red_df, visible_char_map, df2 = val_df, batch_size = params['train_batch'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "101e9213-11dc-402c-970f-c0e3c1dc35e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22528/2716033047.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_dataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible_char_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "_, test_loader = build_dataloaders(test_df, visible_char_map, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a14f54d-bded-4440-a3f0-efdb293b5581",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet, loaded_state_dict = build_resnet(num_classes, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f17b3040-c1be-4a51-be62-ac1bb9d5fae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc.weight True\n",
      "fc.bias True\n"
     ]
    }
   ],
   "source": [
    "for n, p in resnet.named_parameters():\n",
    "    if 'fc' in n:\n",
    "        print(n, p.requires_grad)\n",
    "    else:\n",
    "        p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7513538-4214-4005-8d25-865d1b1f4dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FasterRCNNBackboneModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, faster_rcnn, num_classes = 54):\n",
    "        super(FasterRCNNBackboneModel, self).__init__()\n",
    "        \n",
    "        self.trans = faster_rcnn.transform\n",
    "        self.backbone = faster_rcnn.backbone\n",
    "        \n",
    "        self.adapt = nn.AdaptiveAvgPool2d((1,1))\n",
    "        \n",
    "        input_feat = 256\n",
    "        \n",
    "        self.classifier = nn.Linear(input_feat, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.trans(x)\n",
    "        out = self.backbone(out[0].tensors)['0']\n",
    "        \n",
    "        out = self.adapt(out).squeeze().squeeze()\n",
    "        \n",
    "        out = self.classifier(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "faster_rcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained = True, pretrained_backbone = True)\n",
    "in_features = faster_rcnn.roi_heads.box_predictor.cls_score.in_features\n",
    "faster_rcnn.roi_heads.box_predictor = FastRCNNPredictor(in_features, 55)\n",
    "faster_rcnn.load_state_dict(torch.load('models/faster_fine_tuned.pt')['model_state_dict'])\n",
    "model = FasterRCNNBackboneModel(faster_rcnn, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "649294d7-1b54-445c-804e-5217e6675436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faster_rcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained = True, pretrained_backbone = True)\n",
    "in_features = faster_rcnn.roi_heads.box_predictor.cls_score.in_features\n",
    "faster_rcnn.roi_heads.box_predictor = FastRCNNPredictor(in_features, 55)\n",
    "faster_rcnn.load_state_dict(torch.load('models/faster_fine_tuned.pt')['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7c25272-0c20-486c-9da2-d66a969c6079",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FasterRCNNBackboneModel(faster_rcnn, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9d0f37-385b-4297-9c92-49385b36f0ee",
   "metadata": {},
   "source": [
    "modules = list(model.children())[:-2]\n",
    "modules[-1] = modules[-1].body\n",
    "modules.append(nn.AdaptiveAvgPool2d((1,1)))\n",
    "modules.append(nn.Linear(in_features=2048, out_features=54, bias=True))\n",
    "#modules.pop(0)\n",
    "model = nn.Sequential(*modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43e4f888-6b66-482b-8c61-6a8e5ee7b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "270912ba-7bf3-4398-bd42-40d1029a5165",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for n, param in model.named_parameters():\n",
    "    if 'classifier' not in n:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e59274a4-5527-40b3-9d22-0968daf462c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_loader, loss_fn, optimizer, scheduler, num_classes = 54):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    train_loss_list = []\n",
    "    print(\"Train loop\")\n",
    "    \n",
    "    concat_pred = np.zeros((1, num_classes))\n",
    "    concat_labels = np.zeros((1, num_classes))\n",
    "    avgprecs = np.zeros(num_classes)\n",
    "    \n",
    "    for i, data in enumerate((train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        images, targets, _ = data\n",
    "        \n",
    "        images = list(image.to(DEVICE) for image in images)\n",
    "        targets = targets.to(DEVICE)\n",
    "        \n",
    "        output = model(images)\n",
    "        \n",
    "        cpuout= output.detach().to('cpu')\n",
    "        pred_scores = cpuout.numpy() \n",
    "        concat_pred = np.append(concat_pred, pred_scores, axis = 0)\n",
    "        concat_labels = np.append(concat_labels, targets.cpu().numpy(), axis = 0)\n",
    "        \n",
    "        loss = loss_fn(output, targets)\n",
    "        \n",
    "        loss_value = loss.item()\n",
    "        train_loss_list.append(loss_value)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f'Batch: {i} of {len(train_loader)}. Loss:',loss_value, \"Mean so far:\", np.mean(train_loss_list))\n",
    "            \n",
    "    concat_pred = concat_pred[1:,:]\n",
    "    concat_labels = concat_labels[1:,:]\n",
    "\n",
    "    for c in range(num_classes):   \n",
    "        avgprecs[c] =  metrics.average_precision_score(concat_labels[:,c], concat_pred[:,c])\n",
    "        \n",
    "    measure = np.mean(avgprecs)\n",
    "\n",
    "    return np.mean(train_loss_list), measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a43694ea-a96a-4dfb-912e-0ddd3964258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loop(model, val_loader, loss_fn, num_classes = 54):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    val_loss_list = []\n",
    "\n",
    "    concat_pred = np.zeros((1, num_classes))\n",
    "    concat_labels = np.zeros((1, num_classes))\n",
    "    avgprecs = np.zeros(num_classes)\n",
    "    \n",
    "    print(\"Validation loop\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate((val_loader)):\n",
    "            images, targets, _ = data\n",
    "\n",
    "            images = list(image.to(DEVICE) for image in images)\n",
    "            targets = targets.to(DEVICE)\n",
    "\n",
    "            output = model(images)\n",
    "            \n",
    "            cpuout= output.detach().to('cpu')\n",
    "            pred_scores = cpuout.numpy() \n",
    "            concat_pred = np.append(concat_pred, pred_scores, axis = 0)\n",
    "            concat_labels = np.append(concat_labels, targets.cpu().numpy(), axis = 0)\n",
    "        \n",
    "            loss = loss_fn(output, targets)\n",
    "            \n",
    "            loss_value = loss.item()\n",
    "            val_loss_list.append(loss_value)\n",
    "            if i % 10 == 0:\n",
    "                print(f'Batch: {i} of {len(val_loader)}. Loss:',loss_value, \"Mean so far:\", np.mean(val_loss_list))\n",
    "            \n",
    "    loss_mean = np.mean(val_loss_list)\n",
    "    print(\"Eval loss:\",loss_mean)\n",
    "\n",
    "    concat_pred = concat_pred[1:,:]\n",
    "    concat_labels = concat_labels[1:,:]\n",
    "\n",
    "    for c in range(num_classes):   \n",
    "        avgprecs[c]=  metrics.average_precision_score(concat_labels[:,c], concat_pred[:,c])\n",
    "        \n",
    "    measure = np.mean(avgprecs)\n",
    "        \n",
    "    return loss_mean, measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "476383cd-871f-4e62-9316-62ba817c5b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, loss_fn, optimizer, scheduler, epochs = 5,  model_name = 'resnet', save_path = 'models'):\n",
    "    \n",
    "    train_losses = []\n",
    "    train_avg_prec_list = []\n",
    "    val_losses = []\n",
    "    val_avg_prec_list = []\n",
    "    \n",
    "    best_val_loss = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        tic = time.time()\n",
    "        train_loss, train_avg_prec = train_loop(model, train_loader, loss_fn, optimizer, scheduler)\n",
    "        train_losses.append(train_loss)\n",
    "        train_avg_prec_list.append(train_avg_prec)\n",
    "        \n",
    "        print(\"Train loss:\", train_loss, train_avg_prec)\n",
    "        print(f\"Train loop took {time.time()-tic}\")\n",
    "        tic = time.time()\n",
    "        val_loss, val_avg_prec = val_loop(model, val_loader, loss_fn)\n",
    "        print(\"Validation loss:\", val_loss, val_avg_prec)\n",
    "        print(f\"Validation loop took {time.time()-tic}\")\n",
    "        val_losses.append(val_loss)\n",
    "        val_avg_prec_list.append(val_avg_prec)\n",
    "        #scheduler.step()\n",
    "        \n",
    "        if not best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            \n",
    "            model_name_pt = model_name+'.pt'\n",
    "            PATH = os.path.join(save_path, model_name_pt)\n",
    "            model.to('cpu')\n",
    "            #torch.save(model.state_dict(), PATH)\n",
    "            torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            }, PATH)\n",
    "            model.to(DEVICE)\n",
    "            \n",
    "        else:\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                \n",
    "                model_name_pt = model_name+'.pt'\n",
    "                PATH = os.path.join(save_path, model_name_pt)\n",
    "                model.to('cpu')\n",
    "                torch.save(model.state_dict(), PATH)\n",
    "                model.to(DEVICE)\n",
    "    \n",
    "    return train_losses, val_losses, train_avg_prec, val_avg_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "439b4db4-27cb-46d3-976b-5f4f842df201",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_state_dict = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fb6dfa3-e60c-4b9b-b86a-d0d88ffbdd18",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train loop\n",
      "Batch: 0 of 2500. Loss: 0.8642555475234985 Mean so far: 0.8642555475234985\n",
      "Batch: 10 of 2500. Loss: 0.548582136631012 Mean so far: 0.509785692800175\n",
      "Batch: 20 of 2500. Loss: 0.40228840708732605 Mean so far: 0.46864643409138634\n",
      "Batch: 30 of 2500. Loss: 0.3988168239593506 Mean so far: 0.4439778135668847\n",
      "Batch: 40 of 2500. Loss: 0.40225085616111755 Mean so far: 0.43224306004803353\n",
      "Batch: 50 of 2500. Loss: 0.363121896982193 Mean so far: 0.4229491072542527\n",
      "Batch: 60 of 2500. Loss: 0.3746149241924286 Mean so far: 0.4162500163570779\n",
      "Batch: 70 of 2500. Loss: 0.3509426712989807 Mean so far: 0.41201846574393797\n",
      "Batch: 80 of 2500. Loss: 0.37690404057502747 Mean so far: 0.4082700220155127\n",
      "Batch: 90 of 2500. Loss: 0.3812686800956726 Mean so far: 0.40653348296553227\n",
      "Batch: 100 of 2500. Loss: 0.3916255831718445 Mean so far: 0.4046802467638903\n",
      "Batch: 110 of 2500. Loss: 0.4290059506893158 Mean so far: 0.40388093526298935\n",
      "Batch: 120 of 2500. Loss: 0.4124187231063843 Mean so far: 0.40290144849414666\n",
      "Batch: 130 of 2500. Loss: 0.376723051071167 Mean so far: 0.40176646468293575\n",
      "Batch: 140 of 2500. Loss: 0.3867831230163574 Mean so far: 0.40014611321983606\n",
      "Batch: 150 of 2500. Loss: 0.40476658940315247 Mean so far: 0.400700838163199\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16510/2540817435.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"models/{model_name}.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_avg_prec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_avg_prec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_16510/1570750896.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, loss_fn, optimizer, scheduler, epochs, model_name, save_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch: {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_avg_prec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_avg_prec_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_avg_prec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16510/318568511.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, train_loader, loss_fn, optimizer, scheduler, num_classes)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mcpuout\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mpred_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcpuout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mconcat_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss(weight=None, reduction='mean')\n",
    "\n",
    "optimizer = torch.optim.Adam(train_params, lr = params['lr'], weight_decay = 0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = len(train_loader) * 5)\n",
    "if loaded_state_dict:\n",
    "    optimizer.load_state_dict(torch.load(f\"models/{model_name}.pt\")['optimizer_state_dict'])\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[2,4], gamma = 0.1)\n",
    "    scheduler.load_state_dict(torch.load(f\"models/{model_name}.pt\")['optimizer_state_dict'])\n",
    "\n",
    "train_losses, val_losses, train_avg_prec, val_avg_prec = train(model, train_loader, val_loader, loss_fn, optimizer, scheduler, epochs = 5, model_name = params['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80e489-9380-4f01-ba50-80587972b287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62652469-a8f0-4078-b6eb-a5e38a61c67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39e8d32-6019-4023-bdfd-f49e71f4dea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5e0ea02-204f-4662-922e-07fd9d12b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, param in model.named_parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48704c43-8e0f-4d5c-ad03-b365ccdd504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sam in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66455602-682c-4dc7-b88f-83904643364a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d72eee-ae8b-4faa-be81-5bc855b4302c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d19cc-85fb-4c01-bfd7-558c9dfb531c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss(weight=None, reduction='mean')\n",
    "\n",
    "optimizer = torch.optim.Adam(train_params, lr = 0.0001, weight_decay = 0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = len(train_loader) * 5)\n",
    "\n",
    "\n",
    "train_losses, val_losses, train_avg_prec, val_avg_prec = train(model, train_loader, val_loader, loss_fn, optimizer, scheduler, epochs = 5, model_name = 'resnet_lots_of_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9114af0b-0d94-42e5-98fa-a707b00bcb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52deb9a-4dc7-49d7-887e-919dccab35ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc681a1e-3519-44e3-a072-1e3d44f9f0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1a76bf8-da47-4104-840a-8e769930cf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train loop\n",
      "Batch: 0 of 1250. Loss: 0.23639686405658722 Mean so far: 0.23639686405658722\n",
      "Batch: 10 of 1250. Loss: 0.23683181405067444 Mean so far: 0.24067470024932514\n",
      "Batch: 20 of 1250. Loss: 0.23840096592903137 Mean so far: 0.2413082562741779\n",
      "Batch: 30 of 1250. Loss: 0.2547518014907837 Mean so far: 0.24146087563806964\n",
      "Batch: 40 of 1250. Loss: 0.23345978558063507 Mean so far: 0.2414681886027499\n",
      "Batch: 50 of 1250. Loss: 0.2467907816171646 Mean so far: 0.24195251949861937\n",
      "Batch: 60 of 1250. Loss: 0.24534589052200317 Mean so far: 0.2422728650882596\n",
      "Batch: 70 of 1250. Loss: 0.23527628183364868 Mean so far: 0.24176179229373662\n",
      "Batch: 80 of 1250. Loss: 0.23909978568553925 Mean so far: 0.24234734199665212\n",
      "Batch: 90 of 1250. Loss: 0.24108436703681946 Mean so far: 0.24189489359384056\n",
      "Batch: 100 of 1250. Loss: 0.23411546647548676 Mean so far: 0.24162543498643554\n",
      "Batch: 110 of 1250. Loss: 0.24754904210567474 Mean so far: 0.2416993160774042\n",
      "Batch: 120 of 1250. Loss: 0.23959331214427948 Mean so far: 0.24145971842048583\n",
      "Batch: 130 of 1250. Loss: 0.24382047355175018 Mean so far: 0.24139512813728276\n",
      "Batch: 140 of 1250. Loss: 0.24251464009284973 Mean so far: 0.2414041947811208\n",
      "Batch: 150 of 1250. Loss: 0.24710288643836975 Mean so far: 0.2413462588921288\n",
      "Batch: 160 of 1250. Loss: 0.23224098980426788 Mean so far: 0.24116344860992076\n",
      "Batch: 170 of 1250. Loss: 0.23563523590564728 Mean so far: 0.24075903076874583\n",
      "Batch: 180 of 1250. Loss: 0.22639890015125275 Mean so far: 0.24066733079061983\n",
      "Batch: 190 of 1250. Loss: 0.24545489251613617 Mean so far: 0.2408542100203599\n",
      "Batch: 200 of 1250. Loss: 0.2417244017124176 Mean so far: 0.24084422703999192\n",
      "Batch: 210 of 1250. Loss: 0.24903765320777893 Mean so far: 0.24093900868113008\n",
      "Batch: 220 of 1250. Loss: 0.23900943994522095 Mean so far: 0.2408575309752339\n",
      "Batch: 230 of 1250. Loss: 0.2359335720539093 Mean so far: 0.24107953364198859\n",
      "Batch: 240 of 1250. Loss: 0.2512875199317932 Mean so far: 0.2412256045089223\n",
      "Batch: 250 of 1250. Loss: 0.23986567556858063 Mean so far: 0.24107275956655402\n",
      "Batch: 260 of 1250. Loss: 0.24343594908714294 Mean so far: 0.24111405951309936\n",
      "Batch: 270 of 1250. Loss: 0.24822556972503662 Mean so far: 0.24102581949471547\n",
      "Batch: 280 of 1250. Loss: 0.25018230080604553 Mean so far: 0.2409311949782524\n",
      "Batch: 290 of 1250. Loss: 0.22866880893707275 Mean so far: 0.24078902827505394\n",
      "Batch: 300 of 1250. Loss: 0.25765541195869446 Mean so far: 0.24080644686554753\n",
      "Batch: 310 of 1250. Loss: 0.2345392107963562 Mean so far: 0.24084275462619745\n",
      "Batch: 320 of 1250. Loss: 0.23608872294425964 Mean so far: 0.2408000951244081\n",
      "Batch: 330 of 1250. Loss: 0.23808324337005615 Mean so far: 0.24069894710696355\n",
      "Batch: 340 of 1250. Loss: 0.2514166533946991 Mean so far: 0.24073881181803616\n",
      "Batch: 350 of 1250. Loss: 0.24329502880573273 Mean so far: 0.24064954100680827\n",
      "Batch: 360 of 1250. Loss: 0.23737363517284393 Mean so far: 0.24071703132995279\n",
      "Batch: 370 of 1250. Loss: 0.2507825195789337 Mean so far: 0.24077858822043693\n",
      "Batch: 380 of 1250. Loss: 0.23502953350543976 Mean so far: 0.24085938206964277\n",
      "Batch: 390 of 1250. Loss: 0.21813037991523743 Mean so far: 0.2408408908664113\n",
      "Batch: 400 of 1250. Loss: 0.2459656447172165 Mean so far: 0.240816093888366\n",
      "Batch: 410 of 1250. Loss: 0.22334013879299164 Mean so far: 0.24089213955576402\n",
      "Batch: 420 of 1250. Loss: 0.24574662744998932 Mean so far: 0.24086693633622058\n",
      "Batch: 430 of 1250. Loss: 0.24831828474998474 Mean so far: 0.2409076204225248\n",
      "Batch: 440 of 1250. Loss: 0.2529647946357727 Mean so far: 0.2409243725932915\n",
      "Batch: 450 of 1250. Loss: 0.23659765720367432 Mean so far: 0.24088238721544092\n",
      "Batch: 460 of 1250. Loss: 0.23704205453395844 Mean so far: 0.24096480173557802\n",
      "Batch: 470 of 1250. Loss: 0.24217860400676727 Mean so far: 0.24101841626906345\n",
      "Batch: 480 of 1250. Loss: 0.23736043274402618 Mean so far: 0.24095317953713472\n",
      "Batch: 490 of 1250. Loss: 0.23129406571388245 Mean so far: 0.2409477942222976\n",
      "Batch: 500 of 1250. Loss: 0.24562424421310425 Mean so far: 0.24096262767286358\n",
      "Batch: 510 of 1250. Loss: 0.24056416749954224 Mean so far: 0.24093874650342123\n",
      "Batch: 520 of 1250. Loss: 0.24457138776779175 Mean so far: 0.24091532225801024\n",
      "Batch: 530 of 1250. Loss: 0.24672433733940125 Mean so far: 0.24095986912591758\n",
      "Batch: 540 of 1250. Loss: 0.2524324953556061 Mean so far: 0.24100691022251539\n",
      "Batch: 550 of 1250. Loss: 0.24034087359905243 Mean so far: 0.24100965242528655\n",
      "Batch: 560 of 1250. Loss: 0.23415710031986237 Mean so far: 0.2410167512515437\n",
      "Batch: 570 of 1250. Loss: 0.24374325573444366 Mean so far: 0.24100026822340676\n",
      "Batch: 580 of 1250. Loss: 0.24566441774368286 Mean so far: 0.24101528368903108\n",
      "Batch: 590 of 1250. Loss: 0.2413417398929596 Mean so far: 0.24107300277087088\n",
      "Batch: 600 of 1250. Loss: 0.24062827229499817 Mean so far: 0.24103642305895415\n",
      "Batch: 610 of 1250. Loss: 0.23386065661907196 Mean so far: 0.2410813130304193\n",
      "Batch: 620 of 1250. Loss: 0.24322517216205597 Mean so far: 0.24103387842335755\n",
      "Batch: 630 of 1250. Loss: 0.2339625507593155 Mean so far: 0.24103862732034856\n",
      "Batch: 640 of 1250. Loss: 0.2475235015153885 Mean so far: 0.24101747651460947\n",
      "Batch: 650 of 1250. Loss: 0.24173623323440552 Mean so far: 0.24099740026641733\n",
      "Batch: 660 of 1250. Loss: 0.24409233033657074 Mean so far: 0.24098481073321806\n",
      "Batch: 670 of 1250. Loss: 0.24010729789733887 Mean so far: 0.241052657143725\n",
      "Batch: 680 of 1250. Loss: 0.2317470759153366 Mean so far: 0.2409749399547885\n",
      "Batch: 690 of 1250. Loss: 0.22931349277496338 Mean so far: 0.24096123302724703\n",
      "Batch: 700 of 1250. Loss: 0.2351132035255432 Mean so far: 0.24099052911053032\n",
      "Batch: 710 of 1250. Loss: 0.24706600606441498 Mean so far: 0.24098962446892144\n",
      "Batch: 720 of 1250. Loss: 0.22341622412204742 Mean so far: 0.24101695377023144\n",
      "Batch: 730 of 1250. Loss: 0.23996426165103912 Mean so far: 0.2410227282918103\n",
      "Batch: 740 of 1250. Loss: 0.25178107619285583 Mean so far: 0.2410020712617277\n",
      "Batch: 750 of 1250. Loss: 0.24114128947257996 Mean so far: 0.24098274873671297\n",
      "Batch: 760 of 1250. Loss: 0.24352402985095978 Mean so far: 0.2410074188306673\n",
      "Batch: 770 of 1250. Loss: 0.24715639650821686 Mean so far: 0.24099501184684294\n",
      "Batch: 780 of 1250. Loss: 0.24598227441310883 Mean so far: 0.24100053344737551\n",
      "Batch: 790 of 1250. Loss: 0.2471693605184555 Mean so far: 0.24101902429584304\n",
      "Batch: 800 of 1250. Loss: 0.223669171333313 Mean so far: 0.2409846611720941\n",
      "Batch: 810 of 1250. Loss: 0.23939920961856842 Mean so far: 0.24100783818232588\n",
      "Batch: 820 of 1250. Loss: 0.24686357378959656 Mean so far: 0.24099334626119406\n",
      "Batch: 830 of 1250. Loss: 0.24870136380195618 Mean so far: 0.2409794538065558\n",
      "Batch: 840 of 1250. Loss: 0.24241097271442413 Mean so far: 0.24093517177382776\n",
      "Batch: 850 of 1250. Loss: 0.25185123085975647 Mean so far: 0.24088661171294548\n",
      "Batch: 860 of 1250. Loss: 0.24876870214939117 Mean so far: 0.24091906224255225\n",
      "Batch: 870 of 1250. Loss: 0.23221082985401154 Mean so far: 0.24091523067959414\n",
      "Batch: 880 of 1250. Loss: 0.2398015856742859 Mean so far: 0.240863668881399\n",
      "Batch: 890 of 1250. Loss: 0.22901517152786255 Mean so far: 0.24087797535121375\n",
      "Batch: 900 of 1250. Loss: 0.23873232305049896 Mean so far: 0.2409109284193746\n",
      "Batch: 910 of 1250. Loss: 0.23287871479988098 Mean so far: 0.24087230887358066\n",
      "Batch: 920 of 1250. Loss: 0.22864151000976562 Mean so far: 0.24081496837731942\n",
      "Batch: 930 of 1250. Loss: 0.2375214546918869 Mean so far: 0.24078487087077152\n",
      "Batch: 940 of 1250. Loss: 0.23474180698394775 Mean so far: 0.24079755430013797\n",
      "Batch: 950 of 1250. Loss: 0.24858559668064117 Mean so far: 0.24077720432439437\n",
      "Batch: 960 of 1250. Loss: 0.23952323198318481 Mean so far: 0.24078879296841657\n",
      "Batch: 970 of 1250. Loss: 0.23854167759418488 Mean so far: 0.24081280488371234\n",
      "Batch: 980 of 1250. Loss: 0.24433813989162445 Mean so far: 0.2407631413226949\n",
      "Batch: 990 of 1250. Loss: 0.23514726758003235 Mean so far: 0.24079273848613023\n",
      "Batch: 1000 of 1250. Loss: 0.23073507845401764 Mean so far: 0.24075378596663594\n",
      "Batch: 1010 of 1250. Loss: 0.23222015798091888 Mean so far: 0.24073172591324493\n",
      "Batch: 1020 of 1250. Loss: 0.2521561086177826 Mean so far: 0.24071205253407257\n",
      "Batch: 1030 of 1250. Loss: 0.23918455839157104 Mean so far: 0.2407082062138734\n",
      "Batch: 1040 of 1250. Loss: 0.2461424171924591 Mean so far: 0.24069093645878645\n",
      "Batch: 1050 of 1250. Loss: 0.2551991045475006 Mean so far: 0.2407729233252673\n",
      "Batch: 1060 of 1250. Loss: 0.24544821679592133 Mean so far: 0.24077494161573926\n",
      "Batch: 1070 of 1250. Loss: 0.23097248375415802 Mean so far: 0.24073368649021917\n",
      "Batch: 1080 of 1250. Loss: 0.23804233968257904 Mean so far: 0.2407372765911607\n",
      "Batch: 1090 of 1250. Loss: 0.24889765679836273 Mean so far: 0.240739701034059\n",
      "Batch: 1100 of 1250. Loss: 0.2436007261276245 Mean so far: 0.2407142115954807\n",
      "Batch: 1110 of 1250. Loss: 0.23695194721221924 Mean so far: 0.24067834407278915\n",
      "Batch: 1120 of 1250. Loss: 0.2338367998600006 Mean so far: 0.24065637379804963\n",
      "Batch: 1130 of 1250. Loss: 0.23559975624084473 Mean so far: 0.24063567776368003\n",
      "Batch: 1140 of 1250. Loss: 0.2399543821811676 Mean so far: 0.2406825163351873\n",
      "Batch: 1150 of 1250. Loss: 0.24120068550109863 Mean so far: 0.24066707871200518\n",
      "Batch: 1160 of 1250. Loss: 0.23049579560756683 Mean so far: 0.2406670556409312\n",
      "Batch: 1170 of 1250. Loss: 0.23708368837833405 Mean so far: 0.2406545386138276\n",
      "Batch: 1180 of 1250. Loss: 0.23294618725776672 Mean so far: 0.24065680327453823\n",
      "Batch: 1190 of 1250. Loss: 0.23638513684272766 Mean so far: 0.24063750095571618\n",
      "Batch: 1200 of 1250. Loss: 0.2450578212738037 Mean so far: 0.24064324025706785\n",
      "Batch: 1210 of 1250. Loss: 0.26506906747817993 Mean so far: 0.24068447088624306\n",
      "Batch: 1220 of 1250. Loss: 0.24144284427165985 Mean so far: 0.24070316300491737\n",
      "Batch: 1230 of 1250. Loss: 0.24346467852592468 Mean so far: 0.2406936813354686\n",
      "Batch: 1240 of 1250. Loss: 0.23209582269191742 Mean so far: 0.24068848854778851\n",
      "Train loss: 0.2406772475004196 0.5147574834387599\n",
      "Train loop took 2590.4267563819885\n",
      "Validation loop\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25083/543433774.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_avg_prec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_avg_prec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'resnet_lots_of_data_another_one'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_25083/799117545.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, loss_fn, optimizer, scheduler, epochs, model_name, save_path)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train loop took {time.time()-tic}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_avg_prec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_avg_prec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation loop took {time.time()-tic}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25083/4059778964.py\u001b[0m in \u001b[0;36mval_loop\u001b[0;34m(model, val_loader, loss_fn, num_classes)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "train_params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss(weight=None, reduction='mean')\n",
    "\n",
    "optimizer = torch.optim.Adam(train_params, lr = 0.00001, weight_decay = 0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = len(train_loader) * 5)\n",
    "\n",
    "\n",
    "train_losses, val_losses, train_avg_prec, val_avg_prec = train(model, train_loader, val_loader, loss_fn, optimizer, scheduler, epochs = 5, model_name = 'resnet_lots_of_data_another_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f38fa3-ac37-48e0-9593-f42831769991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07e79b40-b9f8-486e-9c19-f6f26cc42711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resnet.load_state_dict(torch.load('models/resnet_re_train_fine_tuned.pt')['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb97695-42e9-4037-ae34-331dc4424ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1af5d35-5d5c-4d0d-89dd-adeccc38ccfd",
   "metadata": {},
   "source": [
    "# Validation loop and checking the performance per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c78dcc5-ed22-4fdd-944e-5954d4fe911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loop_return_everything(model, val_loader, loss_fn, num_classes = 54):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    val_loss_list = []\n",
    "\n",
    "    concat_pred = np.zeros((1, num_classes))\n",
    "    concat_labels = np.zeros((1, num_classes))\n",
    "    avgprecs = np.zeros(num_classes)\n",
    "    \n",
    "    print(\"Validation loop\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate((val_loader)):\n",
    "            images, targets, _ = data\n",
    "\n",
    "            images = images.to(DEVICE)\n",
    "            targets = targets.to(DEVICE)\n",
    "\n",
    "            output = model(images)\n",
    "            \n",
    "            cpuout= output.detach().to('cpu')\n",
    "            pred_scores = cpuout.numpy() \n",
    "            concat_pred = np.append(concat_pred, pred_scores, axis = 0)\n",
    "            concat_labels = np.append(concat_labels, targets.cpu().numpy(), axis = 0)\n",
    "        \n",
    "            loss = loss_fn(output, targets)\n",
    "            \n",
    "            loss_value = loss.item()\n",
    "            val_loss_list.append(loss_value)\n",
    "            if i % 10 == 0:\n",
    "                print(f'Batch: {i} of {len(val_loader)}. Loss:',loss_value)\n",
    "            \n",
    "    loss_mean = np.mean(val_loss_list)\n",
    "    print(\"Eval loss:\",loss_mean)\n",
    "\n",
    "    concat_pred = concat_pred[1:,:]\n",
    "    concat_labels = concat_labels[1:,:]\n",
    "\n",
    "    for c in range(num_classes):   \n",
    "        avgprecs[c]=  metrics.average_precision_score(concat_labels[:,c], concat_pred[:,c])\n",
    "        \n",
    "    measure = np.mean(avgprecs)\n",
    "        \n",
    "    return loss_mean, measure, avgprecs, concat_pred, concat_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f08caaa-2b63-4000-bcc0-e23c16e493c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loop\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12880/3551063373.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loop_return_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_12880/3493536831.py\u001b[0m in \u001b[0;36mval_loop_return_everything\u001b[0;34m(model, val_loader, loss_fn, num_classes)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss(weight=None, reduction='mean')\n",
    "\n",
    "ret = val_loop_return_everything(resnet, val_loader, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8f5d9e0-9257-45b4-9010-9dc03d970d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c142812c-fb91-4260-baaf-e917e604d2fd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9870158440830942\n",
      "0.9860802837457596\n",
      "0.0008444061645094373\n",
      "0.9615192426217706\n",
      "0.4052841994340145\n",
      "0.6426328663811259\n",
      "0.7506891736348382\n",
      "0.7506141921024738\n",
      "0.4818765946896204\n",
      "0.5054226232132538\n",
      "0.48720178325831887\n",
      "0.4774082281751355\n",
      "0.5656422401310055\n",
      "0.47246565545210506\n",
      "0.8902608096686703\n",
      "0.0362953773407202\n",
      "0.9892332474261584\n",
      "0.10100706537101628\n",
      "0.24392540706476712\n",
      "0.9988255537189779\n",
      "0.95352623850222\n",
      "0.9989855430593186\n",
      "0.7281443152115609\n",
      "1.0\n",
      "0.8780345905556952\n",
      "0.9993825393768674\n",
      "0.9943368170768624\n",
      "0.9989856941377634\n",
      "0.7281443152115609\n",
      "0.41310317631677457\n",
      "0.9978124722321937\n",
      "0.9936409320849163\n",
      "0.9895038258427693\n",
      "0.08517321676222847\n",
      "1.0\n",
      "0.06268768298934228\n",
      "0.057532173820173976\n",
      "0.07075368668074615\n",
      "0.9987485582052075\n",
      "0.3547880845835218\n",
      "0.07094818271289594\n",
      "0.13005071247256356\n",
      "0.05575620379992699\n",
      "0.036658599604282076\n",
      "0.06177173029169289\n",
      "0.056742231672242294\n",
      "0.08818458080452635\n",
      "0.12918121948209244\n",
      "0.12218780461106363\n",
      "0.05597095270485711\n",
      "0.10611170698554667\n",
      "0.9938983333284515\n",
      "0.17054877440805938\n",
      "0.09434183395531875\n"
     ]
    }
   ],
   "source": [
    "for i in ret[-3]:\n",
    "    print(np.mean(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18d1bac3-a8e4-4fe3-953a-eb313c23633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map = {v: k for k, v in visible_char_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff63215e-487c-45c5-b3b6-3bcacf68ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_classes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5b24c2f-6286-4bd4-aaa4-e42e9a64065b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " '0',\n",
       " '1',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '\\\\cdot',\n",
       " '\\\\cot',\n",
       " '\\\\csc',\n",
       " '\\\\sec',\n",
       " '\\\\theta',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'e',\n",
       " 'g',\n",
       " 'h',\n",
       " 'k',\n",
       " 'n',\n",
       " 'p',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1838029a-95f9-4749-aea6-f6ce2e46acb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". 0.0008444061645094373\n",
      "0 0.4052841994340145\n",
      "1 0.6426328663811259\n",
      "4 0.4818765946896204\n",
      "5 0.5054226232132538\n",
      "6 0.48720178325831887\n",
      "7 0.4774082281751355\n",
      "8 0.5656422401310055\n",
      "9 0.47246565545210506\n",
      "\\cdot 0.0362953773407202\n",
      "\\cot 0.10100706537101628\n",
      "\\csc 0.24392540706476712\n",
      "\\sec 0.41310317631677457\n",
      "\\theta 0.08517321676222847\n",
      "a 0.06268768298934228\n",
      "b 0.057532173820173976\n",
      "c 0.07075368668074615\n",
      "e 0.3547880845835218\n",
      "g 0.07094818271289594\n",
      "h 0.13005071247256356\n",
      "k 0.05575620379992699\n",
      "n 0.036658599604282076\n",
      "p 0.06177173029169289\n",
      "r 0.056742231672242294\n",
      "s 0.08818458080452635\n",
      "t 0.12918121948209244\n",
      "u 0.12218780461106363\n",
      "v 0.05597095270485711\n",
      "w 0.10611170698554667\n",
      "y 0.17054877440805938\n",
      "z 0.09434183395531875\n"
     ]
    }
   ],
   "source": [
    "for k,v in visible_char_map.items():\n",
    "    if ret[-3][v-1] < 0.7:\n",
    "        print(k, ret[-3][v-1])\n",
    "        bad_classes.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a3a85-a683-46bb-9f2d-0f20edaf7016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ba0a9-b7c5-453c-83d2-9754768e2a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48836d4-897d-4bc1-ac6f-cb0a2e22fbbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb32dbd-0804-4d70-914d-9a8edc705251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17c7c7d1-4862-4936-8a1c-c82f4a04b202",
   "metadata": {},
   "source": [
    "# Check distribution of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "947603c3-3f63-43d2-9740-83c4f4728708",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'+': 1,\n",
       " '-': 2,\n",
       " '.': 3,\n",
       " '/': 4,\n",
       " '0': 5,\n",
       " '1': 6,\n",
       " '2': 7,\n",
       " '3': 8,\n",
       " '4': 9,\n",
       " '5': 10,\n",
       " '6': 11,\n",
       " '7': 12,\n",
       " '8': 13,\n",
       " '9': 14,\n",
       " '=': 15,\n",
       " '\\\\cdot': 16,\n",
       " '\\\\cos': 17,\n",
       " '\\\\cot': 18,\n",
       " '\\\\csc': 19,\n",
       " '\\\\frac': 20,\n",
       " '\\\\infty': 21,\n",
       " '\\\\left(': 22,\n",
       " '\\\\left|': 23,\n",
       " '\\\\lim_': 24,\n",
       " '\\\\ln': 25,\n",
       " '\\\\log': 26,\n",
       " '\\\\pi': 27,\n",
       " '\\\\right)': 28,\n",
       " '\\\\right|': 29,\n",
       " '\\\\sec': 30,\n",
       " '\\\\sin': 31,\n",
       " '\\\\sqrt': 32,\n",
       " '\\\\tan': 33,\n",
       " '\\\\theta': 34,\n",
       " '\\\\to': 35,\n",
       " 'a': 36,\n",
       " 'b': 37,\n",
       " 'c': 38,\n",
       " 'd': 39,\n",
       " 'e': 40,\n",
       " 'g': 41,\n",
       " 'h': 42,\n",
       " 'k': 43,\n",
       " 'n': 44,\n",
       " 'p': 45,\n",
       " 'r': 46,\n",
       " 's': 47,\n",
       " 't': 48,\n",
       " 'u': 49,\n",
       " 'v': 50,\n",
       " 'w': 51,\n",
       " 'x': 52,\n",
       " 'y': 53,\n",
       " 'z': 54}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visible_char_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bca45275-425f-4271-bb24-d5e05ff92e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3091/2650629691.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m54\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tmp = torch.zeros(54)\n",
    "for idx, i in enumerate(train_loader):\n",
    "    tmp = tmp + i[1].sum(axis=0)\n",
    "    if idx % 100 == 0:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f750cf8-b572-4d10-901c-db5ee07cd3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.9298,  1.4389, -0.8893, -0.1376, -0.2303,  0.1438,  1.5588,  1.0133,\n",
       "         0.5252,  0.5106,  0.4954,  0.4978,  0.5105,  0.5309, -0.4883, -0.8576,\n",
       "         0.1215, -0.7701, -0.6210,  2.6319, -0.0322,  0.4716, -0.7094,  3.2357,\n",
       "        -0.4863, -0.7141,  0.3107,  0.4716, -0.7094, -0.4457,  0.4176, -0.5564,\n",
       "         0.2592, -0.7272,  3.2357, -0.7084, -0.7120, -0.7118, -0.4455, -0.6560,\n",
       "        -0.7155, -0.5469, -0.7136, -0.7504, -0.7094, -0.7257, -0.7300, -0.5891,\n",
       "        -0.5475, -0.7215, -0.5469, -0.1463, -0.5447, -0.7146])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.int()\n",
    "(tmp.int()-tmp.mean()) /tmp.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "103faa92-b403-4db6-a252-8645851f5079",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_2 = torch.zeros(54)\n",
    "for j in val_loader:\n",
    "    tmp_2 = tmp_2 + j[1].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f27dec1-585d-4310-95f4-470134668d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.9091,  1.4448, -0.8898, -0.1522, -0.2285,  0.1663,  1.5614,  1.0286,\n",
       "         0.5391,  0.5095,  0.5288,  0.5185,  0.5025,  0.5301, -0.4851, -0.8564,\n",
       "         0.1238, -0.7657, -0.6158,  2.6429, -0.0142,  0.4510, -0.6998,  3.2292,\n",
       "        -0.4983, -0.6940,  0.2944,  0.4510, -0.6998, -0.4716,  0.3995, -0.5560,\n",
       "         0.2771, -0.7229,  3.2292, -0.7126, -0.7126, -0.7072, -0.4617, -0.6706,\n",
       "        -0.7175, -0.5292, -0.7159, -0.7649, -0.7336, -0.7398, -0.7212, -0.5824,\n",
       "        -0.5535, -0.7048, -0.5680, -0.1353, -0.5474, -0.7085])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tmp_2.int()-tmp_2.mean()) /tmp_2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ed4cbb3-eeb5-4adc-8b78-7c7b69ea5bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'+': 1,\n",
       " '-': 2,\n",
       " '.': 3,\n",
       " '/': 4,\n",
       " '0': 5,\n",
       " '1': 6,\n",
       " '2': 7,\n",
       " '3': 8,\n",
       " '4': 9,\n",
       " '5': 10,\n",
       " '6': 11,\n",
       " '7': 12,\n",
       " '8': 13,\n",
       " '9': 14,\n",
       " '=': 15,\n",
       " '\\\\cdot': 16,\n",
       " '\\\\cos': 17,\n",
       " '\\\\cot': 18,\n",
       " '\\\\csc': 19,\n",
       " '\\\\frac': 20,\n",
       " '\\\\infty': 21,\n",
       " '\\\\left(': 22,\n",
       " '\\\\left|': 23,\n",
       " '\\\\lim_': 24,\n",
       " '\\\\ln': 25,\n",
       " '\\\\log': 26,\n",
       " '\\\\pi': 27,\n",
       " '\\\\right)': 28,\n",
       " '\\\\right|': 29,\n",
       " '\\\\sec': 30,\n",
       " '\\\\sin': 31,\n",
       " '\\\\sqrt': 32,\n",
       " '\\\\tan': 33,\n",
       " '\\\\theta': 34,\n",
       " '\\\\to': 35,\n",
       " 'a': 36,\n",
       " 'b': 37,\n",
       " 'c': 38,\n",
       " 'd': 39,\n",
       " 'e': 40,\n",
       " 'g': 41,\n",
       " 'h': 42,\n",
       " 'k': 43,\n",
       " 'n': 44,\n",
       " 'p': 45,\n",
       " 'r': 46,\n",
       " 's': 47,\n",
       " 't': 48,\n",
       " 'u': 49,\n",
       " 'v': 50,\n",
       " 'w': 51,\n",
       " 'x': 52,\n",
       " 'y': 53,\n",
       " 'z': 54}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visible_char_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9fb8bd-4d29-4a29-a250-c4a8571378b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(model, test_loader):\n",
    "    \n",
    "    model = model.eval()\n",
    "    test_loss_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(tqdm(test_loader)):\n",
    "            images, targets, _ = data\n",
    "\n",
    "            images = list(image.to(DEVICE) for image in images)\n",
    "            targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            out = model(images, targets)\n",
    "\n",
    "            losses = sum(l for l in loss.values())\n",
    "\n",
    "            loss_value = losses.item()\n",
    "            val_loss_list.append(loss_value)\n",
    "            \n",
    "    loss_mean = np.mean(val_loss_list)\n",
    "    print(\"Eval loss:\",loss_mean)\n",
    "        \n",
    "    return loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e25d759-ea20-43ed-b537-f077e275bdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loop\n",
      "Batch: 0 of 63. Loss: 0.25578728318214417\n",
      "Batch: 10 of 63. Loss: 0.2570032775402069\n",
      "Batch: 20 of 63. Loss: 0.27196961641311646\n",
      "Batch: 30 of 63. Loss: 0.2888139486312866\n",
      "Batch: 40 of 63. Loss: 0.2780291438102722\n",
      "Batch: 50 of 63. Loss: 0.28471431136131287\n",
      "Batch: 60 of 63. Loss: 0.2738357186317444\n",
      "Eval loss: 0.27238586355769445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_ranking.py:864: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    }
   ],
   "source": [
    "a = val_loop(model, test_loader, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e73d0ce-f228-4918-9809-a638a345bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_, concat_pred, concat_labels = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8e1316d-7c6c-4160-991a-b029a288ccce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58596671, -0.0599956 , -4.38828087, ..., -2.49682307,\n",
       "        -2.52478766, -2.7654357 ],\n",
       "       [ 2.59002328, -0.49211001, -5.47638988, ..., -2.8251071 ,\n",
       "        -3.16462708, -3.21002603],\n",
       "       [ 0.84441227,  0.1477924 , -4.38981915, ..., -2.51568341,\n",
       "        -2.34248924, -2.6786375 ],\n",
       "       ...,\n",
       "       [ 0.41429237,  0.14224967, -5.43825483, ...,  0.1576449 ,\n",
       "        -3.03038526, -3.68416119],\n",
       "       [-0.65875429, -0.70756537, -4.95354319, ..., -3.03540778,\n",
       "        -2.58185124, -3.12093306],\n",
       "       [ 2.99820757, -0.37740004, -4.89705801, ..., -2.35423446,\n",
       "        -2.75874138, -2.97725725]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1e0c8-3329-4a70-889f-a827c97896e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text_border(draw_obj, font, text, xmin, ymin):\n",
    "    \"\"\"\n",
    "    Add a thin black border around the text, helps with visualization. Modifies the draw object in place.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    draw_obj : PIL.ImageDraw.ImageDraw\n",
    "        The draw object.\n",
    "    font : PIL.ImageFont.FreeTypeFont\n",
    "        The ImageFont to add a border to.\n",
    "    text : str\n",
    "        The precise text being outlined, generally the label.\n",
    "    xmin, ymin: int\n",
    "        The xmin and ymin for the starting point of the text. (Top-Left)\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Add a thin border.\n",
    "    draw_obj.text((xmin-2, ymin), text, font=font, fill=\"black\")\n",
    "    draw_obj.text((xmin+2, ymin), text, font=font, fill=\"black\")\n",
    "    draw_obj.text((xmin, ymin-2), text, font=font, fill=\"black\")\n",
    "    draw_obj.text((xmin, ymin+2), text, font=font, fill=\"black\")\n",
    "\n",
    "def draw_bounding_boxes_on_image(img, xmins, ymins, xmaxs, ymaxs, labels):\n",
    "    \"\"\"\n",
    "    Draws and labels bounding boxes on source image using ground truth lists of details pertaining to the source image. Modifies the source image in place.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : PIL.Image.Image\n",
    "        The source image.\n",
    "    xmins, ymins, xmaxs, ymaxs : list\n",
    "        A list of the respectful coordinates for the image\n",
    "    labels : list\n",
    "        A list of labels for each character to be drawn.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    draw_obj = ImageDraw.Draw(img)\n",
    "    font_file = \"/kaggle/input/ocr-data/extras/single_example/Roboto-Regular.ttf\"\n",
    "    font = ImageFont.truetype(font_file, 32)\n",
    "    for xmin, ymin, xmax, ymax, label in zip(xmins, ymins, xmaxs, ymaxs, labels):\n",
    "        draw_obj.rectangle([xmin, ymin, xmax, ymax], width=3)\n",
    "        text = str(label.item())\n",
    "        add_text_border(draw_obj, font, text, xmin, ymin)\n",
    "        draw_obj.text((xmin, ymin), text, font=font)\n",
    "        \n",
    "def visualize_predictions(model, loader, num_samples = 5, detection_threshold=0.5):\n",
    "    model.eval()\n",
    "    for i, samp in enumerate(test_loader):\n",
    "        if i == num_samples:\n",
    "            break\n",
    "        images, targets, img_file = samp\n",
    "        images = list(img.to(DEVICE) for img in im)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "        \n",
    "        boxes = outputs[0]['boxes'].cpu().data.numpy()\n",
    "        scores = outputs[0]['scores'].cpu().data.numpy()\n",
    "        \n",
    "        #image = cv2.imread(img_file[0])\n",
    "        #orig_image = image.copy()\n",
    "        #image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        \n",
    "        #boxes = boxes[scores >= detection_threshold].astype(np.int32)\n",
    "        #draw_boxes = boxes.copy()\n",
    "        \n",
    "        xmins = boxes[:,1]\n",
    "        ymins = boxes[:,3]\n",
    "        xmaxs = boxes[:,0]\n",
    "        ymaxs = boxes[:,2]\n",
    "        \n",
    "        labels = out[0]['labels']\n",
    "        \n",
    "        img_fil = img_file[0]\n",
    "        img_display = Image.open(img_fil)\n",
    "        #img_display = img_display.resize((896, 896))\n",
    "        \n",
    "        \"\"\"\n",
    "        for j, box in enumerate(draw_boxes):\n",
    "            class_name = pred_classes[j]\n",
    "            color = COLORS[CLASSES.index(class_name)]\n",
    "            cv2.rectangle(orig_image,\n",
    "                        (int(box[0]), int(box[1])),\n",
    "                        (int(box[2]), int(box[3])),\n",
    "                        color, 2)\n",
    "            cv2.putText(orig_image, class_name, \n",
    "                        (int(box[0]), int(box[1]-5)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, \n",
    "                        2, lineType=cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('Prediction', orig_image)\n",
    "        \"\"\"\n",
    "        \n",
    "        draw_bounding_boxes_on_image(img_display, xmins, ymins, xmaxs, ymaxs, labels)\n",
    "        \n",
    "        display(img_display)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3fb2b5-6ef8-486f-93d7-d52631036676",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c2bbd7-578d-4dfe-897d-d44ea50429e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c33ea3-2ac9-41f7-a939-40ba2cfc4de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f62999-9c93-4d9c-a630-277dff439c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "im, targets,_ = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cadd933-84b6-46a7-bb55-e832a1b9f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list(img.to(DEVICE) for img in im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa75b592-601d-4d5e-aac4-0fbb048d1d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeccbbd5-d0e9-451a-92c9-3449986945a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad0ea1-9a1d-41ba-a673-ab41ad7cb83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.width.mean(), df.height.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
